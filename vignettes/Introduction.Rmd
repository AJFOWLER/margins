<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{Introduction to 'margins'}
-->

# 'margins'

**margins** is an effort to port Stata's (closed source) [`margins`](http://www.stata.com/help.cgi?margins) command to R as an S3 generic method for calculating the marginal effects (or "partial effects") of covariates included in model objects (like those of classes "lm" and "glm"). A plot method for the new "margins" class additionally ports the `marginsplot` command.

Stata's `margins` command is very simple and intuitive to use:

```
. import delimited mtcars.csv
. quietly reg mpg c.cyl##c.hp wt
. margins, dydx(*)
------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         cyl |   .0381376   .5998897     0.06   0.950    -1.192735     1.26901
          hp |  -.0463187    .014516    -3.19   0.004     -.076103   -.0165343
          wt |  -3.119815    .661322    -4.72   0.000    -4.476736   -1.762894
------------------------------------------------------------------------------
. marginsplot
```

![marginsplot](http://i.imgur.com/VhoaFGp.png)

With **margins** in R, replicating Stata's results is incredibly simple using just the `margins()` method to obtain average marginal effects:

```{r margins}
library("margins")
x <- lm(mpg ~ cyl * hp + wt, data = mtcars)
(m <- margins(x))
summary(m)
```

With the exception of differences in rounding, the above results match identically what Stata's `margins` command produces. Using the `plot()` method also yields an aesthetically similar result to Stata's `marginsplot`:

```{r marginsplot}
plot(m[[1]])
```


## Marginal Effects Plots

Using `margins` to calculate marginal effects enables several kinds of plotting. The built-in `plot` method for objects of class `margins` creates simple diagnostic plots for examining the output of `margins` in visual rather than tabular format. It is also possible to use the output of `margins` to produce more typical marginal effects plots that show the marginal effect of one variable across levels of another variable. This vignette walks through the `plot` method and then shows how to produce marginal effects plots using base graphics.

### The `plot()` method for "margins" objects

The **margins** package implements a `plot()` method for objects of class "margins" (seen above). This produces a plot similar (in spirit) to the output of Stata's `marginsplot`. It is highly customizable, but is meant primarily as a diagnostic tool to examine the results of `margins`. It simply produces, by default, a plot of marginal effects along with 95% confidence intervals for those effects. The confidence level can be modified using the `levels` argument, which is vectorized to allow multiple levels to be specified simultaneously.

### More advanced plotting

There are two common ways of visually representing the substantive results of a regression model: (1) fitted values plots, which display the fitted conditional mean outcome across levels of a covariate, and (2) marginal effects plots, which display the estimated marginal effect of a variable across levels of a covariate. This section discusses both approaches. Fitted value plots can be created using R's `predict()` function or the wrapper to it provided by `margins::prediction()`, and both types of plots can be implemented using new functions `cplot()` (to provide condition predicted value or effect plots) and a `persp()` method for "lm" objects to display the same type of relationships in three-dimensions (i.e., across two conditioning covariates).

For example, we can use `cplot()` to quickly display the predicted fuel economy of a vehicle from a model:


```{r, results = "hold"}
x <- lm(mpg ~ cyl + wt * am, data = mtcars)
cplot(x, "cyl")
cplot(x, "wt")
```

The slopes of the predicted value lines are the marginal effect of `wt` when `am == 0` and `am == 1`. We can obtain these slopes using `margins` and specifying the `at` argument:

```{r}
margins(x, at = list(am = 0:1))
```

The above plot also highlights, though, that the marginal effect of transmission `am` differs across values of `wt`. As weight increases, the effect of a manual transmission goes from positive (where the blue line is higher than the red line) to negative (where the red line exceed the blue line). Because `am` is an indicator variable, the marginal effect is simply the first-difference (i.e., the difference between the two sets of values we just predicted that are now stored in `p`). We can plot the differences between predicted values to see how the marginal effect of `am` increases (in negative magnitude):

```{r, results = "hold"}
me <- p[3,] - p[1,]
plot(tmp_wt, me, type = "l", ylim = c(-15,15), lwd = 2, xlab = "wt", ylab = "Marginal Effect at Means")
abline(h = 0, col = 'gray')
s <- sqrt(p[4,]^2 + p[2,]^2)
lines(tmp_wt, me + 1.96 * s, lty = 2, lwd = 1)
lines(tmp_wt, me - 1.96 * s, lty = 2, lwd = 1)
```

The marginal effect of `am` is now clear. It is positive when weight is low, indistinguishable from zero for much of the range of weight, and then negative when weight is very high.

But, that's a lot of code to create a plot of marginal effects. Using `margins`, we can produce an essentially identical plot much more easily. Starting again from the same regression model estimation, we can produce the plot quite easily:

```{r, results = "hold"}
x <- lm(mpg ~ cyl + wt * am, data = mtcars)

# calculate marginal effects at specified `wt`s and extract results
tmp_wt <- seq(min(mtcars$wt), max(mtcars$wt), .05)
m <- margins(x, at = list(wt = tmp_wt))
me <- sapply(m, function(z) summary(z)["am",c(2,6,7)])

# draw plot
plot(tmp_wt, me[1,], type = "l", ylim = c(-15,15), lwd = 2, xlab = "wt", ylab = "Marginal Effect at Means")
abline(h = 0, col = 'gray')
lines(tmp_wt, me[2,], lty = 2, lwd = 1)
lines(tmp_wt, me[3,], lty = 2, lwd = 1)
```


It is also possible to do this with **ggplot2**. Starting from the list of marginal effects results (`m`) from above, we can replace the base plotting code with simple ggplot2 code:

```{r, results = "hold"}
me <- do.call(rbind, lapply(m, function(z) summary(z)["am",c(2,6,7)]))
me$x <- as.numeric(row.names(me))
names(me) <- c("e","l","u","x") # rename columns for simplicity

library("ggplot2")
ggplot(me) + geom_line(aes(x=x, y=e, group=1)) + 
   geom_hline(yintercept=0, linetype=2, color="dark gray") +
   geom_line(aes(x=x, y=u, group=1), stat="identity", alpha=.3, color="black") + 
   geom_line(aes(x=x, y=l, group=1), stat="identity", alpha=.3, color="black") + 
   xlab("wt") + ylab("Marginal Effect") + theme_bw() 
```






## Using Optional Arguments in `margins`

**margins** is intended as a port of (some of) the features of Stata's `margins` command, which includes numerous options for calculating marginal effects at the mean values of a dataset (i.e., the marginal effects at the mean), an average of the marginal effects at each value of a dataset (i.e., the average marginal effect), marginal effects at representative values, and any of those operations on various subsets of a dataset. In particular, Stata provides the following options:

 - `atmeans`: calculate marginal effects at the mean (MEMs) of a dataset rather than the default behavior of calculating average marginal effects (AMEs)
 - `at`: calculate marginal effects at (potentially representative) specified values (i.e., replacing observed values with specified replacement values before calculating marginal effects)
 - `over`: calculate marginal effects (including MEMs and/or AMEs at observed or specified values) on subsets of the original data (e.g., the marginal effect of a treatment separately for men and women)
 
Stata's `atmeans` argument is translated into `margins` as a simple logical argument. The default (`atmeans = FALSE`) produces AMEs; `atmeans = TRUE` produces MEMs.

The `at` argument has also been translated into `margins`. It can be used by specifying a list of variable names and specified values for those variables at which to calculate marginal effects. When using `at`, `margins` constructs modified datasets containing the specified values and calculates marginal effects on each modified dataset.

At present, `margins` does not implement the `over` option. The reason for this is simple: R already makes data subsetting operations quite simple using simple `[` extraction. If, for example, one wanted to calculate marginal effects on subsets of a data.frame, those subsets can be passed directly to `margins` via the `newdata` argument (as in a call to `predict` from the **stats** package).

The rest of this vignette shows how to use `at`, `atmeans`, and `newdata` to obtain various kinds of marginal effects.

---

### AMEs versus MEMs

```{r, echo = FALSE, results = 'hide'}
options(width = 100)
```

We can start by loading the **margins** package:

```{r}
library("margins")
```

We'll use a simple example regression model based on the `mtcars` dataset:

```{r}
x <- lm(mpg ~ cyl + hp * wt, data = mtcars)
```

To obtain average marginal effects (AMEs), we simply call `margins` on the model object created by `lm`:

```{r}
margins(x)
```

The result is a list containing a single object of class `"margins"`. `"margins"` objects are printed in a tidy summary format, by default, as you can see above. To instead obtain marginal effects at the means (MEMs), we simply add `atmeans = TRUE` to the function call:

```{r}
margins(x, atmeans = TRUE)
```

Of course in an ordinary least squares regression, this option makes no difference for the resulting marginal effects because the regression coefficients are marginal effects. In a generalized linear model (e.g., logit), however, this difference would be consequential as can be seen in the trivial example below. Note that if marginal effects were calculated on the log-odds or latent scale (using option `type = "link"`), the `atmeans` option would also be inconsequential. But, examing marginal effects on the probability scale (using option `type = "response"`), there is a difference in the apparent marginal effects of the terms included in the explicit interaction: `hp` and `wt`. In a large sample, the difference between AMEs and MEMs would likely disappear.

```{r}
x <- glm(am ~ cyl + hp * wt, data = mtcars, family = binomial)
# AMEs
margins(x, type = "response")
# MEMs
margins(x, atmeans = TRUE, type = "response")
```

---

### Using the `at` Argument

The `at` argument allows you to calculate marginal effects at representative cases (sometimes "MERs"), which are marginal effects for particularly interesting (sets of) observations in a dataset. This differs from marginal effects on subsets of the original data (see the next section for a demonstration of that). This is helpful because it allows for calculation of marginal effects for counterfactual datasets. For example, if we wanted to know if the marginal effect of horsepower (`hp`) on fuel economy differed across different types of transmissions, we could simply use `at` to obtain separate marginal effect estimates for our data as if every car observation were a manual versus if every car observation were an automatic.

```{r, results = "hold"}
x <- lm(mpg ~ cyl + wt + hp * am, data = mtcars)
margins(x, at = list(am = 0:1))
```

Because of the `hp * am` interaction in the regression, the marginal effect of horsepower differs between the two sets of results. We can also specify more than one variable to `at`, creating a potentially long list of marginal effects results. For example, we can produce marginal effects at both levels of `am` and the values from the five-number summary (minimum, Q1, median, Q3, and maximum) of observed values of `hp`. This produces 2 * 5 = 10 sets of marginal effects estimates. We'll see the first three below:

```{r, results = "hold"}
m <- margins(x, at = list(am = 0:1, hp = fivenum(mtcars$hp)))
m[1:3] # first three summaries
```

Because this is a linear model, the marginal effects of `cyl` and `wt` do not vary across levels of `am` or `hp`. The minimum and Q1 value of `hp` are also the same, so the marginal effects of `am` are the same in the first two results tables. As you can see, however, the marginal effect of `hp` differs when `am == 0` versus `am == 1` (first and second results tables) and the marginal effect of `am` differs across levels of `hp` (e.g., between the first and third tables). As should be clear, the `at` argument is incredibly useful for getting a better grasp of the marginal effects of different covariates.

This becomes especially apparent when a model includes power-terms (or any other alternative form of a covariate). Consider, for example, the simple model of fuel economy as a function of weight, with weight included as both a first- and second-order term:

```{r, results = "hold"}
x <- lm(mpg ~ wt + I(wt^2), data = mtcars)
summary(x)
```

Looking only at the regression results table, it is actually quite difficult to understand the effect of `wt` on fuel economy because it requires performing mental multiplication and addition on all possible values of `wt`. Using the `at` option to margins, you could quickly obtain a sense of the average marginal effect of `wt` at a range of plausible values:

```{r, results = "hold"}
wt_tmp <- fivenum(mtcars$wt)
m <- margins(x, at = list(wt = wt_tmp))
t(sapply(m, summary))[,-1]
```

The marginal effects in the first column of results reveal that the average marginal effect of `wt` is large and negative except when `wt` is very large, in which case it has an effect not distinguishable from zero. We can easily plot these results using the `cplot()` function to see the effect visually in terms of either predicted fuel economy or the marginal effect of `wt`:

```{r}
cplot(x, "wt", what = "prediction", main = "Predicted Fuel Economy, Given Weight")
cplot(x, "wt", what = "effect", main = "Average Marginal Effect of Weight")
```

A really nice feature of Stata's margins command is that it handles factor variables gracefully. This functionality is difficult to emulate in R, but the `margins` function does its best. Here we see the marginal effects of a simple regression that includes a factor variable:

```{r}
x <- lm(mpg ~ factor(cyl) * hp + wt, data = mtcars)
margins(x)
```

`margins` recognizes the factor and displays the marginal effect for each level of the factor separately. This may not work with `at` specifications (yet).

